# Cluster_EMR
Terraform Configuration that handles the creation of an ElasticMap Reduce cluster

The set up has to be able to handle:

1. Create and properly handle the VPC where the cluster will be allocated 
2. All network, creation and configurations
3. Security Groups
4. Handle all S3 operations in order to have proper input and output to the EMR cluster
5. Profiles and Roles for IAM
6. The EMR Cluster itself

---

#Manual Steps

##Creation of S3 Bucket

Because we want to use the remote tfstate configuration, we want a safe place to store it. Due that, we have to create a S3 bucket on AWS. It is recommended to enable the versioning capabilities of S3, so all changes into our current infrastructure are safely saved.

## EC2 Pem file

A Pem file generated/available with capabilities to reach ec2 machines will be needed. This file could be located into the cfg folder. This folder it is not tracked by git nor are the files with *.pem* extension.

## Configuration

The default configuration is customized to run without any problem on sa-east-1. So, certain machine types and specs will need tune in order to properly run on your machine. Please check all variable 3 variable files (one on root folder, and the other 2 located at each module), in order to set up your default parameters based on the region that you will use.

### VPC Module

* aws_instance.nat.instance_type: this parameter will vary depending on your needs. Before run, check availability of the type for your machine and the type of virtualization depending on the AMI.

### EMC Module

* aws_emr_cluster.tf-test-cluster.master_instance_type -> emc.variables.master_type: Type definition for the master machine. May vary depending on your needs and region
* aws_emr_cluster.tf-test-cluster.core_instance_type -> emv.variables.core_type: Type definition for the slave machines. May vary depending on your needs and region.
* aws_emr_clister.tf-test-clister.applications -> emv.variables.apps: list with all the applications that you want to run on the cluster. Based on [this thread](https://groups.google.com/forum/#!topic/terraform-tool/Ve9hBzsAZys "AWS EMR Applications"), the list available should be: "MapR"|"HUE"|"HIVE"|"PIG"|"HBASE"|"IMPALA"|"GANGLIA"|"HADOOP"|"SPARK"
* aws_emr_clister.tf-test-clister.core_instance_count: Number of machines that will be on the cluster. Remember if you want 3 workers, you have to select 4 because the master is also on this count

---

#Project Configuration 

Before plan to build our infrastructure, we need to setup the project through the **setup.sh** script. This script will create the *cfg folder*, where the credentials and the base tfvars file.

The script will ask:

* AWS access key
* AWS secret key
* S3 bucket name
* S3 bucket region
* Give a project name for the current infrastructure ran

## Build the infrastructure

After configure the files and run the setup, you will need to have installed [Terraform](https://www.terraform.io/ "Terraform web site"). This script was built using Terraform v0.8.7.

###Plan your infrastructure

> terraform plan -var 'aws_pem=<name>' -var 'pem_folder_path=<path_to_your_pem>/<name>.pem

### Build and Apply to AWS 
> terraform apply -var 'aws_pem=<name>' -var 'pem_folder_path=<path_to_your_pem>/<name>.pem

###Tear down your infrastructure
> terraform destroy -var 'aws_pem=<name>' -var 'pem_folder_path=<path_to_your_pem>/<name>.pem

---

#File Structure

The structure given to the project is sorted by modules. This gives the possibility to easily add or remove modules as needed. 

##Root Folder

###Terraform files

* main.tf: also known as provider.tf. This file specify the provider used on the current project
* outputs.tf: Organized data that is generated by this project and could be easily queried by others

###Module related Files
* vpc.tf: In charge to handle the creation of all resources related to the creation of a VPC

###Variables

* terraform.tfvars: Variables that are part needed for the project but may vary from users/projects
* initialize.tf: Variables that may be initialized through terraform.tfvars or provided by the user at runtime
* variables.tf: Variables which has already default options, but if the user needs, can be provided too

##Modules Folder

###VPC

* nat.tf: Configuration for a nat instance and its corresponding elastic ip
* outputs.tf
* sg.tf: Configuration for basic security groups
* subnets.tf: Configuration for private and public subnets into the VPC
* variables.tf
* vpc.tf: Main file of the module. Responsible to create the VPC and the gateway

##EMC
* arn.tf: Configuration for Roles and Profiles that will be used by the ElasticMap Reduce Cluster
* emr.tf: Main file for the ElasticMapReduce Cluster. 
* s3.tf: Configuration that will handle s3 bucket
* variables.tf

---
# Known Issues

* Sometimes, its now allowed the creation of certain machine on a specific availability zone due the instance type. If this is the error, please destroy and recreate all again. If you are sure which region and availability zone will be used, then this value could be hard coded.
* In order to properly destroy all resources, it is needed to first destroy all automatically not-related-to-terraform resources. Commonly those are security groups (because EMC creation) and files into the s3 buckets

---

#TO DO
* Keep the pem information as extra variable only adds complexity to the calls, so could be better if this variable is added into the initialize file either on setup time or as manual input.
* The default map data is too long to complex, so as this configuration evolves, default data (as availability zones, default ami's, or even other configurations for emc will be added. 
* Since are too many different configurations for EMC based on user needs, its complex to automate all of those. If the user want to have those steps automated too, will have to have a better understand of the whole process and do it manually using as a template this whole project.

